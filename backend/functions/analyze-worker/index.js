/**
 * AnalyzeWorkerFunction - SQS Worker for async novel analysis
 * 
 * ä»Ž SQS Queue æŽ¥æ”¶æ¶ˆæ¯å¹¶æ‰§è¡Œå®žé™…çš„å°è¯´åˆ†æžä»»åŠ¡ã€‚
 * è¿™ä¸ª Worker å‡½æ•°å¤„ç†é•¿æ—¶é—´è¿è¡Œçš„ Qwen API è°ƒç”¨å’Œæ•°æ®åº“å†™å…¥ã€‚
 * 
 * @module AnalyzeWorkerFunction
 */

const { DynamoDBClient } = require('@aws-sdk/client-dynamodb');
const { DynamoDBDocumentClient, GetCommand, PutCommand, UpdateCommand, BatchWriteCommand } = require('@aws-sdk/lib-dynamodb');
const { S3Client, GetObjectCommand } = require('@aws-sdk/client-s3');
const { SecretsManagerClient, GetSecretValueCommand } = require('@aws-sdk/client-secrets-manager');
const Ajv = require('ajv');
const { v4: uuid } = require('uuid');

const QwenAdapter = require('../../lib/qwen-adapter');
const BibleManager = require('../../lib/bible-manager');

// AWS Clients
const dynamodbClient = new DynamoDBClient({});
const docClient = DynamoDBDocumentClient.from(dynamodbClient);
const s3Client = new S3Client({});
const secretsClient = new SecretsManagerClient({});

// AJV validator - å®½å®¹æ¨¡å¼ï¼ŒåªéªŒè¯ç»“æž„ï¼Œä¸éªŒè¯ç±»åž‹ä¸¥æ ¼æ€§
const ajv = new Ajv({ 
  allErrors: true,
  strict: false,           // ä¸ä½¿ç”¨ä¸¥æ ¼æ¨¡å¼
  coerceTypes: true,       // è‡ªåŠ¨ç±»åž‹è½¬æ¢ï¼ˆå¦‚ "18" -> 18ï¼‰
  useDefaults: true,       // ä½¿ç”¨é»˜è®¤å€¼
  removeAdditional: false  // ä¿ç•™é¢å¤–çš„å­—æ®µ
});

// Environment variables
const TABLE_NAME = process.env.TABLE_NAME;
const ASSETS_BUCKET = process.env.ASSETS_BUCKET;
const QWEN_SECRET_ARN = process.env.QWEN_SECRET_ARN;
const BIBLES_TABLE_NAME = process.env.BIBLES_TABLE_NAME;
const BIBLES_BUCKET = process.env.BIBLES_BUCKET || ASSETS_BUCKET;

// Load schemas
const storyboardSchema = require('../../schemas/storyboard.json');
const validateStoryboard = ajv.compile(storyboardSchema);

// Cache for Qwen credentials
let qwenAdapterCache = null;
function getBibleManager() {
  if (!BIBLES_TABLE_NAME) {
    throw new Error('BIBLES_TABLE_NAME environment variable not set');
  }
  if (!BIBLES_BUCKET) {
    throw new Error('BIBLES_BUCKET or ASSETS_BUCKET environment variable not set');
  }
  console.log('[AnalyzeWorker] BibleManager initialized');
  return new BibleManager(docClient, s3Client, BIBLES_TABLE_NAME, BIBLES_BUCKET);
}


/**
 * Get Qwen API credentials from Secrets Manager
 */
async function getQwenAdapter() {
  if (qwenAdapterCache) {
    return qwenAdapterCache;
  }
  
  if (!QWEN_SECRET_ARN) {
    throw new Error('QWEN_SECRET_ARN environment variable not set');
  }
  
  console.log('[AnalyzeWorker] Fetching Qwen credentials from Secrets Manager');
  
  const response = await secretsClient.send(
    new GetSecretValueCommand({ SecretId: QWEN_SECRET_ARN })
  );
  
  const secret = JSON.parse(response.SecretString);
  
  // Support both naming conventions: apiKey/endpoint (old) and QWEN_API_KEY/QWEN_ENDPOINT (new)
  const apiKey = secret.apiKey || secret.QWEN_API_KEY;
  const endpoint = secret.endpoint || secret.QWEN_ENDPOINT;
  const model = secret.model || secret.QWEN_MODEL;
  
  if (!apiKey) {
    console.error('[AnalyzeWorker] Secret contents:', Object.keys(secret));
    throw new Error('API key not found in secret (checked apiKey and QWEN_API_KEY)');
  }
  
  qwenAdapterCache = new QwenAdapter({
    apiKey,
    endpoint,
    model
  });
  
  console.log('[AnalyzeWorker] Qwen adapter initialized');
  return qwenAdapterCache;
}

/**
 * Get novel text from DynamoDB or S3
 */
async function getNovelText(novelId) {
  console.log(`[AnalyzeWorker] Fetching novel ${novelId} from DynamoDB`);
  
  const result = await docClient.send(
    new GetCommand({
      TableName: TABLE_NAME,
      Key: {
        PK: `NOVEL#${novelId}`,
        SK: `NOVEL#${novelId}`
      }
    })
  );
  
  if (!result.Item) {
    throw new Error(`Novel ${novelId} not found`);
  }
  
  const novel = result.Item;
  
  // If text is in S3, fetch it
  if (novel.originalTextS3) {
    console.log(`[AnalyzeWorker] Fetching text from S3: ${novel.originalTextS3}`);
    
    const s3Response = await s3Client.send(
      new GetObjectCommand({
        Bucket: ASSETS_BUCKET,
        Key: novel.originalTextS3.replace(`s3://${ASSETS_BUCKET}/`, '')
      })
    );
    
    const text = await s3Response.Body.transformToString('utf-8');
    return { novel, text };
  }
  
  // Otherwise use text from DynamoDB
  return { novel, text: novel.originalText };
}

/**
 * Update job status and progress
 */
async function updateJob(jobId, status, progress = {}, errorMessage = null) {
  const timestamp = new Date().toISOString();
  
  const updateParams = {
    TableName: TABLE_NAME,
    Key: {
      PK: `JOB#${jobId}`,
      SK: `JOB#${jobId}`
    },
    UpdateExpression: 'SET #status = :status, updatedAt = :updatedAt, progress = :progress',
    ExpressionAttributeNames: {
      '#status': 'status'
    },
    ExpressionAttributeValues: {
      ':status': status,
      ':updatedAt': timestamp,
      ':progress': progress
    }
  };
  
  if (status === 'completed') {
    updateParams.UpdateExpression += ', completedAt = :completedAt';
    updateParams.ExpressionAttributeValues[':completedAt'] = timestamp;
    
    // âœ… å¦‚æžœ progress ä¸­æœ‰ storyboardIdï¼ŒåŒæ—¶æ›´æ–°é¡¶å±‚å­—æ®µ
    if (progress.storyboardId) {
      updateParams.UpdateExpression += ', storyboardId = :storyboardId';
      updateParams.ExpressionAttributeValues[':storyboardId'] = progress.storyboardId;
    }
  }
  
  if (status === 'failed' && errorMessage) {
    updateParams.UpdateExpression += ', errorMessage = :errorMessage';
    updateParams.ExpressionAttributeValues[':errorMessage'] = errorMessage;
  }
  
  await docClient.send(new UpdateCommand(updateParams));
  console.log(`[AnalyzeWorker] Job ${jobId} updated: ${status} (${JSON.stringify(progress)})`);
}

/**
 * Write storyboard data to DynamoDB
 */
async function writeStoryboardToDynamoDB(novelId, userId, storyboard) {
  const storyboardId = uuid();
  const timestamp = new Date().toISOString();
  
  console.log('[AnalyzeWorker] Writing storyboard to DynamoDB');
  console.log(`  - Panels: ${storyboard.panels.length}`);
  console.log(`  - Characters: ${storyboard.characters.length}`);
  console.log(`  - Scenes: ${storyboard.scenes ? storyboard.scenes.length : 0}`);
  
  // 1. Create Storyboard item
  const storyboardItem = {
    PK: `NOVEL#${novelId}`,
    SK: `STORYBOARD#${storyboardId}`,
    id: storyboardId,
    novelId,
    userId,
    totalPanels: storyboard.panels.length,
    totalPages: storyboard.totalPages || Math.ceil(storyboard.panels.length / 6),
    totalCharacters: storyboard.characters.length,
    totalScenes: storyboard.scenes ? storyboard.scenes.length : 0,
    status: 'generated',
    createdAt: timestamp,
    updatedAt: timestamp,
    GSI1PK: `USER#${userId}`,
    GSI1SK: `STORYBOARD#${timestamp}`
  };
  
  await docClient.send(new PutCommand({
    TableName: TABLE_NAME,
    Item: storyboardItem
  }));
  
  console.log(`[AnalyzeWorker] Storyboard ${storyboardId} created`);
  
  // 2. Batch write Panels (max 25 items per batch)
  const panelItems = storyboard.panels.map((panel, idx) => ({
    PK: `STORYBOARD#${storyboardId}`,
    SK: `PANEL#${String(idx).padStart(4, '0')}`,
    id: uuid(),
    storyboardId,
    novelId,
    ...panel,
    status: 'pending',
    createdAt: timestamp,
    updatedAt: timestamp
  }));
  
  // Write panels in batches of 25
  for (let i = 0; i < panelItems.length; i += 25) {
    const batch = panelItems.slice(i, i + 25);
    await docClient.send(new BatchWriteCommand({
      RequestItems: {
        [TABLE_NAME]: batch.map(item => ({
          PutRequest: { Item: item }
        }))
      }
    }));
    console.log(`[AnalyzeWorker] Wrote panels ${i + 1}-${Math.min(i + 25, panelItems.length)}`);
  }
  
  // 3. Write Characters
  const characterItems = storyboard.characters.map(char => ({
    PK: `NOVEL#${novelId}`,
    SK: `CHARACTER#${char.name}`,
    id: uuid(),
    novelId,
    storyboardId,
    ...char,
    createdAt: timestamp,
    updatedAt: timestamp
  }));
  
  for (let i = 0; i < characterItems.length; i += 25) {
    const batch = characterItems.slice(i, i + 25);
    await docClient.send(new BatchWriteCommand({
      RequestItems: {
        [TABLE_NAME]: batch.map(item => ({
          PutRequest: { Item: item }
        }))
      }
    }));
    console.log(`[AnalyzeWorker] Wrote characters ${i + 1}-${Math.min(i + 25, characterItems.length)}`);
  }
  
  // 4. Write Scenes (if present)
  if (storyboard.scenes && storyboard.scenes.length > 0) {
    const sceneItems = storyboard.scenes.map(scene => ({
      PK: `NOVEL#${novelId}`,
      SK: `SCENE#${scene.id}`,
      id: scene.id,
      novelId,
      storyboardId,
      ...scene,
      createdAt: timestamp,
      updatedAt: timestamp
    }));
    
    for (let i = 0; i < sceneItems.length; i += 25) {
      const batch = sceneItems.slice(i, i + 25);
      await docClient.send(new BatchWriteCommand({
        RequestItems: {
          [TABLE_NAME]: batch.map(item => ({
            PutRequest: { Item: item }
          }))
        }
      }));
      console.log(`[AnalyzeWorker] Wrote scenes ${i + 1}-${Math.min(i + 25, sceneItems.length)}`);
    }
  }
  
  // 5. Update Novel with storyboard reference
  await docClient.send(new UpdateCommand({
    TableName: TABLE_NAME,
    Key: {
      PK: `NOVEL#${novelId}`,
      SK: `NOVEL#${novelId}`
    },
    UpdateExpression: 'SET storyboardId = :storyboardId, updatedAt = :updatedAt',
    ExpressionAttributeValues: {
      ':storyboardId': storyboardId,
      ':updatedAt': timestamp
    }
  }));
  
  console.log('[AnalyzeWorker] Novel updated with storyboard reference');
  
  return { storyboardId };
}

/**
 * Main handler - processes SQS messages
 */
exports.handler = async (event) => {
  console.log(`[AnalyzeWorker] Processing ${event.Records.length} messages`);
  
  for (const record of event.Records) {
    // SQS body might be double-encoded, handle both cases
    let messageBody;
    try {
      messageBody = JSON.parse(record.body);
    } catch (e) {
      // If first parse fails, body might already be an object
      messageBody = record.body;
    }
    
    const { jobId, novelId, userId, chapterNumber: rawChapterNumber } = messageBody;
    
    const chapterNumber = (() => {
      if (rawChapterNumber === undefined || rawChapterNumber === null) {
        return 1;
      }
      const parsed = Number(rawChapterNumber);
      if (!Number.isFinite(parsed) || parsed <= 0) {
        return 1;
      }
      return Math.floor(parsed);
    })();
    
    console.log(`[AnalyzeWorker] Received message for job ${jobId}`);
    console.log(`[AnalyzeWorker] Target chapter: ${chapterNumber}`);
    
    try {
      // âœ… IDEMPOTENCY CHECK: Get current job status
      const existingJob = await docClient.send(
        new GetCommand({
          TableName: TABLE_NAME,
          Key: {
            PK: `JOB#${jobId}`,
            SK: `JOB#${jobId}`
          }
        })
      );
      
      if (!existingJob.Item) {
        console.warn(`[AnalyzeWorker] âš ï¸ Job ${jobId} not found in DynamoDB, skipping`);
        continue;
      }
      
      const currentStatus = existingJob.Item.status;
      console.log(`[AnalyzeWorker] Job ${jobId} current status: ${currentStatus}`);
      
      // âœ… Skip if already completed
      if (currentStatus === 'completed') {
        console.log(`[AnalyzeWorker] âœ… Job ${jobId} already completed (storyboardId: ${existingJob.Item.progress?.storyboardId}), skipping duplicate message`);
        continue;
      }
      
      // âœ… Skip if already running (duplicate message from visibility timeout)
      if (currentStatus === 'running') {
        console.log(`[AnalyzeWorker] ðŸ”„ Job ${jobId} already running (stage: ${existingJob.Item.progress?.stage}), skipping duplicate message`);
        continue;
      }
      
      // âœ… Allow retry if failed
      if (currentStatus === 'failed') {
        console.log(`[AnalyzeWorker] ðŸ” Job ${jobId} previously failed, retrying...`);
      }
      
      console.log(`[AnalyzeWorker] ðŸš€ Starting job ${jobId} for novel ${novelId}`);
      
      // âœ… Use conditional update to prevent race conditions
      try {
        const timestamp = new Date().toISOString();
        await docClient.send(new UpdateCommand({
          TableName: TABLE_NAME,
          Key: {
            PK: `JOB#${jobId}`,
            SK: `JOB#${jobId}`
          },
          UpdateExpression: 'SET #status = :running, updatedAt = :updatedAt, progress = :progress',
          ConditionExpression: '#status = :queued OR #status = :failed',
          ExpressionAttributeNames: {
            '#status': 'status'
          },
          ExpressionAttributeValues: {
            ':queued': 'queued',
            ':failed': 'failed',
            ':running': 'running',
            ':updatedAt': timestamp,
            ':progress': { percentage: 5, stage: 'initializing' }
          }
        }));
        console.log(`[AnalyzeWorker] Job ${jobId} updated: running ({"percentage":5,"stage":"initializing"})`);
      } catch (error) {
        if (error.name === 'ConditionalCheckFailedException') {
          console.log(`[AnalyzeWorker] âš¡ Job ${jobId} status changed by another process, skipping`);
          continue;
        }
        throw error;
      }
      
      // 1. Job already set to running above (with conditional check)
      
      // 2. Fetch novel text
      await updateJob(jobId, 'running', { percentage: 10, stage: 'fetching_text' });
      const { novel, text } = await getNovelText(novelId);
      let novelText = text;
      if (!novelText && messageBody.text) {
        console.warn('[AnalyzeWorker] Novel text missing from storage, falling back to message payload');
        novelText = messageBody.text;
      }
      if (!novelText) {
        throw new Error(`Novel ${novelId} text not found in storage or message`);
      }
      console.log(`[AnalyzeWorker] Novel text length: ${novelText.length} chars`);
      
      // 3. Initialize Qwen adapter
      await updateJob(jobId, 'running', { percentage: 20, stage: 'initializing_qwen' });
      const qwenAdapter = await getQwenAdapter();
      
      // 3a. Load existing bible for continuity
      await updateJob(jobId, 'running', { percentage: 25, stage: 'loading_bible' });
      const bibleManager = getBibleManager();
      const existingBible = await bibleManager.getBible(novelId);
      const existingCharacterCount = Array.isArray(existingBible.characters) ? existingBible.characters.length : 0;
      const existingSceneCount = Array.isArray(existingBible.scenes) ? existingBible.scenes.length : 0;
      console.log(`[AnalyzeWorker] Bible loaded: version ${existingBible.version} (characters: ${existingCharacterCount}, scenes: ${existingSceneCount})`);
      
      // 4. Generate storyboard
      await updateJob(jobId, 'running', { percentage: 30, stage: 'generating_storyboard' });
      const storyboard = await qwenAdapter.generateStoryboard({
        text: novelText,
        jsonSchema: storyboardSchema,
        strictMode: true,
        maxChunkLength: 8000,
        existingCharacters: existingBible.characters || [],
        existingScenes: existingBible.scenes || [],
        chapterNumber
      });
      
      console.log('[AnalyzeWorker] Storyboard generated');
      console.log(`  - Panels: ${storyboard.panels.length}`);
      console.log(`  - Characters: ${storyboard.characters.length}`);
      console.log(`  - Scenes: ${storyboard.scenes ? storyboard.scenes.length : 0}`);
      
      // 5. Validate storyboard
      await updateJob(jobId, 'running', { percentage: 85, stage: 'validating' });
      const valid = validateStoryboard(storyboard);
      
      if (!valid) {
        console.error('[AnalyzeWorker] âŒ Storyboard validation failed');
        console.error('[AnalyzeWorker] Validation errors:', JSON.stringify(validateStoryboard.errors, null, 2));
        console.error('[AnalyzeWorker] Generated storyboard structure:', JSON.stringify({
          hasTitle: !!storyboard.title,
          hasSummary: !!storyboard.summary,
          panelsCount: storyboard.panels?.length,
          charactersCount: storyboard.characters?.length,
          scenesCount: storyboard.scenes?.length,
          firstPanel: storyboard.panels?.[0],
          firstCharacter: storyboard.characters?.[0],
          firstScene: storyboard.scenes?.[0]
        }, null, 2));
        
        // Log the FULL storyboard for debugging
        console.error('[AnalyzeWorker] ðŸ“„ Full Generated Storyboard (for debugging):');
        console.error(JSON.stringify(storyboard, null, 2));
        
        throw new Error('Generated storyboard does not match schema');
      }
      
      console.log('[AnalyzeWorker] âœ… Storyboard validated successfully');
      
      // 5a. Save updated bible
      await updateJob(jobId, 'running', { percentage: 88, stage: 'saving_bible' });
      const bibleResult = await bibleManager.saveBible(
        novelId,
        storyboard.characters || [],
        storyboard.scenes || [],
        chapterNumber
      );
      const updatedMetadata = bibleResult.metadata || {};
      const totalCharacters = updatedMetadata.totalCharacters ?? (bibleResult.characters ? bibleResult.characters.length : 0);
      const totalScenes = updatedMetadata.totalScenes ?? (bibleResult.scenes ? bibleResult.scenes.length : 0);
      const storageLocation = updatedMetadata.storageLocation;

      console.log(
        `[AnalyzeWorker] Bible updated to version ${bibleResult.version} ` +
        `(characters: ${totalCharacters}, scenes: ${totalScenes}, ` +
        `storage: ${storageLocation ? 'S3' : 'DynamoDB'})`
      );
      
      // 6. Write to DynamoDB
      await updateJob(jobId, 'running', { percentage: 90, stage: 'writing_database' });
      const { storyboardId } = await writeStoryboardToDynamoDB(novelId, userId, storyboard);
      
      // 7. Mark job as completed
      await updateJob(jobId, 'completed', {
        percentage: 100,
        stage: 'completed',
        storyboardId,
        panelCount: storyboard.panels.length,
        characterCount: storyboard.characters.length,
        sceneCount: storyboard.scenes ? storyboard.scenes.length : 0
      });
      
      console.log(`[AnalyzeWorker] Job ${jobId} completed successfully`);
      
    } catch (error) {
      console.error(`[AnalyzeWorker] Job ${jobId} failed:`, error);
      
      await updateJob(jobId, 'failed', {
        percentage: 0,
        stage: 'failed'
      }, error.message);
      
      console.warn(`[AnalyzeWorker] æ¶ˆæ¯ ${jobId} å°†è¢«æ ‡è®°ä¸ºå·²å¤„ç†ä»¥é¿å…é˜Ÿåˆ—é˜»å¡ž`);
      continue;
    }
  }
  
  return {
    statusCode: 200,
    body: JSON.stringify({ processed: event.Records.length })
  };
};

module.exports.lambdaHandler = exports.handler;
